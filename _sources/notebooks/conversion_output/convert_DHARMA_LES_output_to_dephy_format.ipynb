{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example: convert DHARMA LES output to DEPHY format\n",
    "\n",
    "Code to read DHARMA LES output files and write to DEPHY format (NetCDF)\n",
    "\n",
    "Contributed by Ann Fridlind from NASA/GISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import netCDF4\n",
    "import datetime as dt\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify directory locations\n",
    "\n",
    "If on the ARM JupyterHub, it is recommended to create and specify a local directory that is outside of the COMBLE-MIP repository to upload raw model output files in your model's format. \n",
    "\n",
    "Processed domain-mean outputs are invited for commit to the GitHub repository on a user-specified branch under /comble-mip/output_les/YOUR_MODEL_NAME/sandbox/YOUR_RUN_NAME. These can be committed and removed at any time.\n",
    "\n",
    "It is requested to name your baseline small-domain run directory as 'Lx25km_dx100m' (in place of YOUR_RUN_NAME), so that it can readily be automatically compared with other runs using the same test specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify start time of simulation and simulation name\n",
    "start_dtime = '2020-03-12 22:00:00.0'\n",
    "\n",
    "# specify input data directory name, traceable to source machine, and\n",
    "# specify output file name (see file naming convention in TOC)\n",
    "\n",
    "# FixN with no ice test\n",
    "my_readdir = 'case0313_diagn_ice0_miz_cfmip_dx200'\n",
    "my_outfile = 'DHARMA-MIZ-RAD_Lx25km_dx200_noIce.nc'\n",
    "\n",
    "# FixN with ice test\n",
    "my_readdir = 'dx200_swoff_z0fix1' # \n",
    "my_outfile = 'DHARMA_Lx25km_dx200_z0_4.nc'\n",
    "\n",
    "# ProgNa with ice test\n",
    "my_readdir = 'case0313_diag_ice25_nomiz_dx100_specZ0'\n",
    "my_outfile = 'DHARMA-NOMIZ-RAD_Lx25km_dx100_FixN.nc'\n",
    "\n",
    "# specify local source directories (additional subdirectories if restart was required)\n",
    "\n",
    "my_rundir = '/data/home/floriantornow/dharma/sandbox/' + my_readdir + '/'\n",
    "\n",
    "my_outdirs = sorted([f for f in os.listdir(my_rundir) if not f.startswith('.')], key=str.lower)\n",
    "print(my_outdirs)\n",
    "\n",
    "# specify Github scratch directory where processed model output will be committed\n",
    "my_gitdir = '../../output_les/dharma/sandbox/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DHARMA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read set-up parameters\n",
    "\n",
    "Note: ERROR 1: PROJ... message can be ignored here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in DHARMA parameter settings\n",
    "input_filename = my_rundir + my_outdirs[0] + '/dharma.cdf'\n",
    "dharma_params = xr.open_dataset(input_filename)\n",
    "print(input_filename)\n",
    "\n",
    "# check if the run contains ice variables\n",
    "do_ice = bool(dharma_params['Cond'].do_ice)\n",
    "print('do_ice = ',do_ice)\n",
    "\n",
    "# check for prognostic aerosol\n",
    "do_progNa = bool(dharma_params['Cond'].do_prog_na)\n",
    "print('do_progNa = ',do_progNa)\n",
    "\n",
    "# full parameter list\n",
    "dharma_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read domain-mean profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate DHARMA domain-mean instantaneous profiles and take 10-min average:\n",
    "# resample-average before concatenating and removing duplicates\n",
    "for index, elem in enumerate(my_outdirs):\n",
    "    input_filename = my_rundir + elem + '/dharma.soundings.cdf'\n",
    "    print(input_filename)\n",
    "    if index==0:\n",
    "        dharma_snds = xr.open_dataset(input_filename)\n",
    "        dharma_snds['time'] = pd.to_datetime(dharma_snds['time'].values, unit='s', origin=pd.Timestamp(start_dtime))\n",
    "        dharma_snds = dharma_snds.resample(time=\"600s\",closed=\"right\",label=\"right\").mean()\n",
    "    else:\n",
    "        dharma_snds2 = xr.open_dataset(input_filename)\n",
    "        dharma_snds2['time'] = pd.to_datetime(dharma_snds2['time'].values, unit='s', origin=pd.Timestamp(start_dtime))\n",
    "        dharma_snds2 = dharma_snds2.resample(time=\"600s\",closed=\"right\",label=\"right\").mean()\n",
    "        dharma_snds = xr.concat([dharma_snds,dharma_snds2],dim='time')\n",
    "dharma_snds = dharma_snds.drop_duplicates('time',keep='first')\n",
    "dharma_snds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile unit conversions and sundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dummy sounding and initialize some variables needed\n",
    "dummy_snd = dharma_snds['qc']*0.\n",
    "nz = dharma_params['geometry'].nz\n",
    "dz = dharma_snds['zw'].data[1:nz+1]-dharma_snds['zw'].data[0:nz]\n",
    "cp = 1004.\n",
    "Lhe = 2.50e6\n",
    "Lhs = Lhe + 3.34e5\n",
    "\n",
    "# compute some intermediate quantities for use below\n",
    "Fql_turb = dharma_snds['Fqc_turb'].data+dharma_snds['Fqr_turb'].data\n",
    "if do_ice:\n",
    "    Fqi_turb = dharma_snds['Fqic_turb'].data+dharma_snds['Fqif_turb'].data+dharma_snds['Fqid_turb'].data\n",
    "wql_tot = 0.5*(Fql_turb[:,0:nz]+Fql_turb[:,1:nz+1])/dharma_snds['rhobar'].data+dharma_snds['WQL'].data\n",
    "\n",
    "if do_ice:\n",
    "    wqi_tot = 0.5*(Fqi_turb[:,0:nz]+Fqi_turb[:,1:nz+1])/dharma_snds['rhobar'].data+dharma_snds['WQI'].data\n",
    "else:\n",
    "    wqi_tot = np.nan*wql_tot\n",
    "PFql = dharma_snds['PFqc'].data+dharma_snds['PFqr'].data\n",
    "if do_ice:\n",
    "    PFqi = dharma_snds['PFqic'].data+dharma_snds['PFqif'].data+dharma_snds['PFqid'].data\n",
    "else:\n",
    "    PFqi = np.nan*PFql\n",
    "wpfl = 0.5*(PFql[:,0:nz]+PFql[:,1:nz+1])*-1./3600./dharma_snds['rhobar'].data\n",
    "wpfi = 0.5*(PFqi[:,0:nz]+PFqi[:,1:nz+1])*-1./3600./dharma_snds['rhobar'].data\n",
    "PFqc = dharma_snds['PFqc'].data \n",
    "PFqr = dharma_snds['PFqr'].data \n",
    "if do_ice:\n",
    "    PFqic = dharma_snds['PFqic'].data \n",
    "    PFqif = dharma_snds['PFqif'].data \n",
    "    PFqid = dharma_snds['PFqid'].data \n",
    "if do_progNa:\n",
    "    ssa_sfc = (dharma_snds['Sna_1_sfc'].data[:,0]+dharma_snds['Sna_2_sfc'].data[:,0]+dharma_snds['Sna_3_sfc'].data[:,0])*dharma_snds['zw'].data[1]\n",
    "Flwd = dharma_snds['Flw_dn'].data\n",
    "Flwu = dharma_snds['Flw_up'].data\n",
    "Fnlw = Flwu - Flwd\n",
    "Suvar_adv = dharma_snds['Su2_adv'].data - dharma_snds['Subar2_adv'].data\n",
    "Svvar_adv = dharma_snds['Sv2_adv'].data - dharma_snds['Svbar2_adv'].data\n",
    "Swvar_adv = dharma_snds['Sw2_adv'].data - dharma_snds['Swbar2_adv'].data\n",
    "Stke_a = Suvar_adv + Svvar_adv + 0.5*(Swvar_adv[:,0:nz]+Swvar_adv[:,1:nz+1])\n",
    "Stke_adv_dis = dharma_snds['Stke_adv'].data + dharma_snds['Sprod'].data\n",
    "Smke = (dharma_snds['u'].data-dharma_params.translate.u)*dharma_snds['Suavg_SGS'].data + (dharma_snds['v'].data-dharma_params.translate.v)*dharma_snds['Svavg_SGS'].data\n",
    "Ske = dharma_snds['Su2avg_SGS'].data+dharma_snds['Sv2avg_SGS'].data+dharma_snds['Sw2avg_SGS'].data\n",
    "Stke_dis = Smke - Ske\n",
    "\n",
    "# append new variables to the data structure\n",
    "dharma_snds = dharma_snds.assign(theta = dummy_snd + (dharma_snds['th'].data+1)*dharma_snds.theta_00)\n",
    "dharma_snds = dharma_snds.assign(pi = dummy_snd + dharma_snds['T'].data/dharma_snds['theta'].data)\n",
    "dharma_snds = dharma_snds.assign(pressure = dummy_snd + np.power(dharma_snds['pi'].data,7./2)*np.power(10.,5))\n",
    "dharma_snds = dharma_snds.assign(PF = dummy_snd + 0.5*(PFqc[:,0:nz]+PFqc[:,1:nz+1]) + 0.5*(PFqr[:,0:nz]+PFqr[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(nlcic = dummy_snd + dharma_snds['nc_cld'].data*1.e6/dharma_snds['rhobar'].data)\n",
    "if do_ice:\n",
    "    dharma_snds = dharma_snds.assign(PFi = dummy_snd + 0.5*(PFqic[:,0:nz]+PFqic[:,1:nz+1]) + 0.5*(PFqif[:,0:nz]+PFqif[:,1:nz+1]) \n",
    "                                     + 0.5*(PFqid[:,0:nz]+PFqid[:,1:nz+1]) )\n",
    "    dharma_snds['PF'] += dharma_snds['PFi']\n",
    "else:\n",
    "    dharma_snds['RHI'] = np.nan*dharma_snds['RH']\n",
    "    dharma_snds['PFi'] = np.nan*dharma_snds['PF']\n",
    "dharma_snds = dharma_snds.assign(uw_zt = dummy_snd + 0.5*(dharma_snds['txz_tot'].data[:,0:nz]+dharma_snds['txz_tot'].data[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(vw_zt = dummy_snd + 0.5*(dharma_snds['tyz_tot'].data[:,0:nz]+dharma_snds['tyz_tot'].data[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(w2_zt = dummy_snd + (dharma_snds['w2'].data[:,0:nz]+dharma_snds['w2'].data[:,1:nz+1])) # w2 = 0.5*w'2\n",
    "dharma_snds = dharma_snds.assign(wth_zt = dummy_snd + 0.5*(dharma_snds['qhz_tot'].data[:,0:nz] + \n",
    "                                        dharma_snds['qhz_tot'].data[:,1:nz+1])*dharma_snds.theta_00)\n",
    "dharma_snds = dharma_snds.assign(wthli_zt = dummy_snd + dharma_snds['wth_zt'].data\n",
    "                    - wql_tot*Lhe/(dharma_snds['pi'].data*cp) - wqi_tot*Lhs/(dharma_snds['pi'].data*cp)\n",
    "                    - wpfl*Lhe/(dharma_snds['pi'].data*cp) - wpfi*Lhs/(dharma_snds['pi'].data*cp))                                 \n",
    "dharma_snds = dharma_snds.assign(wqv_zt = dummy_snd + 0.5*(dharma_snds['qqz_tot'].data[:,0:nz]+dharma_snds['qqz_tot'].data[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(wqt_zt = dummy_snd + dharma_snds['wqv_zt'].data + wql_tot + wqi_tot + wpfl + wpfi)\n",
    "dharma_snds = dharma_snds.assign(eps = dummy_snd + Stke_dis + Stke_adv_dis)\n",
    "dharma_snds = dharma_snds.assign(LWdn = dummy_snd + 0.5*(Flwd[:,0:nz]+Flwd[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(LWup = dummy_snd + 0.5*(Flwu[:,0:nz]+Flwu[:,1:nz+1]))\n",
    "dharma_snds = dharma_snds.assign(HRlw = dummy_snd + 0.5*(Fnlw[:,0:nz]+Fnlw[:,1:nz+1])/dz/dharma_snds['rhobar'].data)\n",
    "dharma_snds = dharma_snds.assign(dth_micro = dummy_snd + dharma_snds['Sth_micro'].data + dharma_snds['Sth_cond'].data)\n",
    "dharma_snds = dharma_snds.assign(dq_micro = dummy_snd + dharma_snds['Sqv_micro'].data + dharma_snds['Sqv_cond'].data)\n",
    "dharma_snds = dharma_snds.assign(dth_turb = dummy_snd + (dharma_snds['qhz_tot'].data[:,0:nz] - \n",
    "                                        dharma_snds['qhz_tot'].data[:,1:nz+1])*dharma_snds.theta_00)\n",
    "dharma_snds = dharma_snds.assign(dq_turb = dummy_snd + dharma_snds['qqz_tot'].data[:,0:nz] - dharma_snds['qqz_tot'].data[:,1:nz+1])\n",
    "if do_progNa:\n",
    "    dharma_snds = dharma_snds.assign(na_loss_liq = dummy_snd + dharma_snds['na_loss_prof'].data - dharma_snds['na_loss_ice'].data)\n",
    "    dharma_snds = dharma_snds.assign(dna_mixing = dummy_snd + dharma_snds['Sna_1_adv'].data + dharma_snds['Sna_2_adv'].data + dharma_snds['Sna_3_adv'].data + \n",
    "                                dharma_snds['Sna_1_sfc'].data + dharma_snds['Sna_2_sfc'].data + dharma_snds['Sna_3_sfc'].data)\n",
    "\n",
    "dharma_snds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read domain-mean scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, elem in enumerate(my_outdirs):\n",
    "    input_filename = my_rundir + elem + '/dharma.scalars.cdf'\n",
    "    print(input_filename)\n",
    "    if index==0:\n",
    "        dharma_scas = xr.open_dataset(input_filename)\n",
    "        dharma_scas['time'] = pd.to_datetime(dharma_scas['time'].values, unit='s', origin=pd.Timestamp(start_dtime))\n",
    "        dharma_scas = dharma_scas.resample(time=\"600s\",closed=\"right\",label=\"right\").mean()\n",
    "    else:\n",
    "        dharma_scas2 = xr.open_dataset(input_filename)\n",
    "        dharma_scas2['time'] = pd.to_datetime(dharma_scas2['time'].values, unit='s', origin=pd.Timestamp(start_dtime))\n",
    "        dharma_scas2 = dharma_scas2.resample(time=\"600s\",closed=\"right\",label=\"right\").mean()\n",
    "        dharma_scas = xr.concat([dharma_scas,dharma_scas2],dim='time')\n",
    "dharma_scas = dharma_scas.drop_duplicates('time',keep='first')\n",
    "dharma_scas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate some additional variables requested\n",
    "dummy_sca = dharma_scas['lwp']*0.\n",
    "dharma_scas = dharma_scas.assign(Psurf = dummy_sca + dharma_params['sounding'].Psurf*100.)\n",
    "if do_ice:\n",
    "    dharma_scas = dharma_scas.assign(opd_tot = dummy_sca + dharma_scas['opd_drops'].data + dharma_scas['opd_ice'].data)\n",
    "else:\n",
    "    dharma_scas = dharma_scas.assign(opd_tot = dummy_sca + dharma_scas['opd_drops'].data)\n",
    "    #dharma_scas = dharma_scas.assign(RHI = np.nan*dharma_scas['opd_tot'])\n",
    "dharma_scas = dharma_scas.assign(LWdnSFC = dummy_sca + dharma_snds['Flw_dn'].data[:,0])\n",
    "dharma_scas = dharma_scas.assign(LWupSFC = dummy_sca + dharma_snds['Flw_up'].data[:,0])\n",
    "dharma_scas = dharma_scas.assign(avg_precip_ice = dummy_sca + dharma_scas['avg_precip'].data \n",
    "                                 - dharma_snds['PFqc'].data[:,0] - dharma_snds['PFqr'].data[:,0])\n",
    "if do_progNa:\n",
    "    dharma_scas = dharma_scas.assign(ssaf = dummy_sca + ssa_sfc)\n",
    "dharma_scas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare output file in DEPHY format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read requested variables list\n",
    "\n",
    "Variable description, naming, units, and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read list of requested variables\n",
    "vars_mean_list = pd.read_excel('https://docs.google.com/spreadsheets/d/1Vl8jYGviet7EtXZuQiitrx4NSkV1x27aJAhxxjBb9zI/export?gid=0&format=xlsx',\n",
    "                              sheet_name='Mean')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "vars_mean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match DHARMA variables to requested outputs\n",
    "\n",
    "Expand the table to include columns that indicate DHARMA model variable names and any conversion factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop comments\n",
    "vars_mean_list = vars_mean_list#.drop(columns='comment (10-min average reported at endpoints, green=minimum)')\n",
    "\n",
    "# add columns to contain model output name and units conversion factors\n",
    "vars_mean_list = vars_mean_list.assign(model_name='missing data',conv_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# identify requested variables with only time dimension\n",
    "vars_mean_scas = vars_mean_list[vars_mean_list['dimensions']=='time']\n",
    "\n",
    "# match to DHARMA variable names and specify conversion factors\n",
    "for index in vars_mean_scas.index:\n",
    "    standard_name = vars_mean_list.standard_name.iat[index]\n",
    "    if standard_name=='surface_pressure': \n",
    "        vars_mean_list.model_name.iat[index] = 'Psurf'\n",
    "    if standard_name=='surface_temperature': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_T_sfc'\n",
    "    if standard_name=='surface_friction_velocity': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_ustar'\n",
    "    if standard_name=='surface_roughness_length_for_momentum_in_air':\n",
    "        vars_mean_list.model_name.iat[index] = 'avg_z0'\n",
    "    if standard_name=='surface_roughness_length_for_heat_in_air':\n",
    "        vars_mean_list.model_name.iat[index] = 'avg_z0h'\n",
    "    if standard_name=='surface_roughness_length_for_humidity_in_air':\n",
    "        # same as roughness length for heat in DHARMA\n",
    "        vars_mean_list.model_name.iat[index] = 'avg_z0h'\n",
    "    if standard_name=='surface_upward_sensible_heat_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_T_flx'\n",
    "    if standard_name=='surface_upward_latent_heat_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_qv_flx'\n",
    "    if standard_name=='obukhov_length': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_obk'\n",
    "    if standard_name=='atmosphere_mass_content_of_liquid_cloud_water': \n",
    "        vars_mean_list.model_name.iat[index] = 'cwp'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/1000.\n",
    "    if standard_name=='atmosphere_mass_content_of_rain_water': \n",
    "        vars_mean_list.model_name.iat[index] = 'rwp'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/1000.\n",
    "    if do_ice:\n",
    "        if standard_name=='atmosphere_mass_content_of_ice_water': \n",
    "            vars_mean_list.model_name.iat[index] = 'iwp'\n",
    "            vars_mean_list.conv_factor.iat[index] = 1/1000.\n",
    "    if standard_name=='cloud_area_fraction': \n",
    "        vars_mean_list.model_name.iat[index] = 'colf_opd'\n",
    "    if standard_name=='optical_depth': \n",
    "        vars_mean_list.model_name.iat[index] = 'opd_tot'\n",
    "    if standard_name=='optical_depth_of_liquid_cloud': \n",
    "        vars_mean_list.model_name.iat[index] = 'opd_cloud'\n",
    "    if standard_name=='precipitation_flux_at_surface': \n",
    "        vars_mean_list.model_name.iat[index] = 'avg_precip'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/3600.\n",
    "    if do_ice:\n",
    "        if standard_name=='precipitation_flux_at_surface_in_ice_phase': \n",
    "            vars_mean_list.model_name.iat[index] = 'avg_precip_ice'\n",
    "            vars_mean_list.conv_factor.iat[index] = 1/3600.\n",
    "    if standard_name=='optical_depth_of_cloud_droplets': \n",
    "        vars_mean_list.model_name.iat[index] = 'opd_cloud'\n",
    "    if standard_name=='toa_outgoing_longwave_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'LWupTOA'\n",
    "    if standard_name=='surface_downwelling_longwave_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'LWdnSFC'  \n",
    "    if standard_name=='surface_upwelling_longwave_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'LWupSFC'\n",
    "    if do_progNa:\n",
    "        if standard_name=='surface_sea_spray_number_flux': \n",
    "            vars_mean_list.model_name.iat[index] = 'ssaf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# identify requested variables with time and vertical dimensions\n",
    "vars_mean_snds = vars_mean_list[vars_mean_list['dimensions']=='time, height']\n",
    "\n",
    "# match to DHARMA variable names and specify conversion factors\n",
    "for index in vars_mean_snds.index:\n",
    "    standard_name = vars_mean_list.standard_name.iat[index]\n",
    "    if standard_name=='air_pressure': \n",
    "        vars_mean_list.model_name.iat[index] = 'pressure'\n",
    "    if standard_name=='eastward_wind': \n",
    "        vars_mean_list.model_name.iat[index] = 'u'\n",
    "    if standard_name=='northward_wind': \n",
    "        vars_mean_list.model_name.iat[index] = 'v'\n",
    "    if standard_name=='air_dry_density': \n",
    "        vars_mean_list.model_name.iat[index] = 'rhobar'\n",
    "    if standard_name=='air_temperature': \n",
    "        vars_mean_list.model_name.iat[index] = 'T'\n",
    "    if standard_name=='water_vapor_mixing_ratio': \n",
    "        vars_mean_list.model_name.iat[index] = 'qv'\n",
    "    if standard_name=='relative_humidity': \n",
    "        vars_mean_list.model_name.iat[index] = 'RH'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/100.\n",
    "    if standard_name=='relative_humidity_over_ice': \n",
    "        vars_mean_list.model_name.iat[index] = 'RHI'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/100.\n",
    "    if standard_name=='air_potential_temperature': \n",
    "        vars_mean_list.model_name.iat[index] = 'theta'\n",
    "    if standard_name=='specific_turbulent_kinetic_energy_resolved': \n",
    "        vars_mean_list.model_name.iat[index] = 'tkeavg'\n",
    "    if standard_name=='specific_turbulent_kinetic_energy_sgs': \n",
    "        vars_mean_list.model_name.iat[index] = 'tke_smag'\n",
    "    if standard_name=='mass_mixing_ratio_of_cloud_liquid_water_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'qc'\n",
    "    if standard_name=='mass_mixing_ratio_of_rain_water_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'qr'\n",
    "    if do_ice:\n",
    "        if standard_name=='mass_mixing_ratio_of_cloud_ice_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'qic'\n",
    "        if standard_name=='mass_mixing_ratio_of_snow_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'qif'\n",
    "        if standard_name=='mass_mixing_ratio_of_graupel_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'qid'\n",
    "    if standard_name=='number_of_liquid_cloud_droplets_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'nc'\n",
    "    if standard_name=='number_of_rain_drops_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'nr'\n",
    "    if do_ice:\n",
    "        if standard_name=='number_of_cloud_ice_crystals_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'nic'\n",
    "        if standard_name=='number_of_snow_crystals_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'nif'\n",
    "        if standard_name=='number_of_graupel_crystals_in_air': \n",
    "            vars_mean_list.model_name.iat[index] = 'nid'    \n",
    "    if do_progNa:\n",
    "        if standard_name=='number_of_total_aerosol_mode1': \n",
    "            vars_mean_list.model_name.iat[index] = 'na_1'\n",
    "        if standard_name=='number_of_total_aerosol_mode2': \n",
    "            vars_mean_list.model_name.iat[index] = 'na_2'\n",
    "        if standard_name=='number_of_total_aerosol_mode3': \n",
    "            vars_mean_list.model_name.iat[index] = 'na_3'\n",
    "    if standard_name=='number_of_liquid_cloud_droplets_in_cloud': \n",
    "        vars_mean_list.model_name.iat[index] = 'nlcic'\n",
    "    if do_ice:\n",
    "        if standard_name=='number_of_ice_crystals_in_cloud': \n",
    "            vars_mean_list.model_name.iat[index] = 'niic'\n",
    "    if standard_name=='dissipation_rate_of_turbulent_kinetic_energy': \n",
    "        vars_mean_list.model_name.iat[index] = 'eps'\n",
    "    if standard_name=='zonal_momentum_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'uw_zt'\n",
    "    if standard_name=='meridional_momentum_flux': \n",
    "        vars_mean_list.model_name.iat[index] = 'vw_zt'\n",
    "    if standard_name=='variance_of_upward_air_velocity': \n",
    "        vars_mean_list.model_name.iat[index] = 'w2_zt'\n",
    "    if standard_name=='vertical_flux_potential_temperature': \n",
    "        vars_mean_list.model_name.iat[index] = 'wth_zt'\n",
    "    if standard_name=='vertical_flux_liquid_ice_water_potential_temperature': \n",
    "        vars_mean_list.model_name.iat[index] = 'wthli_zt'\n",
    "    if standard_name=='vertical_flux_water_vapor': \n",
    "        vars_mean_list.model_name.iat[index] = 'wqv_zt'\n",
    "    if standard_name=='vertical_flux_total_water': \n",
    "        vars_mean_list.model_name.iat[index] = 'wqt_zt'\n",
    "    if standard_name=='area_fraction_of_liquid_cloud': \n",
    "        vars_mean_list.model_name.iat[index] = 'cloud_f'\n",
    "    if standard_name=='precipitation_flux_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'PF'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/(3600.)\n",
    "    if standard_name=='precipitation_flux_in_air_in_ice_phase': \n",
    "        vars_mean_list.model_name.iat[index] = 'PFi'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/(3600.)\n",
    "    if standard_name=='downwelling_longwave_flux_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'LWdn'\n",
    "    if standard_name=='upwelling_longwave_flux_in_air': \n",
    "        vars_mean_list.model_name.iat[index] = 'LWup'\n",
    "    if standard_name=='tendency_of_air_potential_temperature_due_to_radiative_heating': \n",
    "        vars_mean_list.model_name.iat[index] = 'Srad'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/3600.\n",
    "    if standard_name=='tendency_of_air_potential_temperature_due_to_microphysics': \n",
    "        vars_mean_list.model_name.iat[index] = 'dth_micro'\n",
    "        vars_mean_list.conv_factor.iat[index] = 1/3600.\n",
    "    if standard_name=='tendency_of_air_potential_temperature_due_to_mixing': \n",
    "        vars_mean_list.model_name.iat[index] = 'dth_turb'\n",
    "    if standard_name=='tendency_of_water_vapor_mixing_ratio_due_to_microphysics': \n",
    "        vars_mean_list.model_name.iat[index] = 'dq_micro'\n",
    "    if standard_name=='tendency_of_water_vapor_mixing_ratio_due_to_mixing': \n",
    "        vars_mean_list.model_name.iat[index] = 'dq_turb'\n",
    "    if do_progNa:\n",
    "        if standard_name=='tendency_of_aerosol_number_due_to_warm_microphysics': \n",
    "            vars_mean_list.model_name.iat[index] = 'na_loss_liq'\n",
    "            vars_mean_list.conv_factor.iat[index] = -1.\n",
    "        if standard_name=='tendency_of_aerosol_number_due_to_mixing': \n",
    "            vars_mean_list.model_name.iat[index] = 'dna_mixing'\n",
    "        if do_ice:\n",
    "            if standard_name=='tendency_of_aerosol_number_due_to_cold_microphysics': \n",
    "                vars_mean_list.model_name.iat[index] = 'na_loss_ice'\n",
    "                vars_mean_list.conv_factor.iat[index] = -1.\n",
    "    if do_ice:\n",
    "        if standard_name=='tendency_of_ice_number_due_to_heterogeneous_freezing': \n",
    "            vars_mean_list.model_name.iat[index] = 'Sice_het'\n",
    "        if standard_name=='tendency_of_ice_number_due_to_secondary_ice_production': \n",
    "            vars_mean_list.model_name.iat[index] = 'Sice_sec'\n",
    "        if standard_name=='tendency_of_ice_number_due_to_homogeneous_freezing': \n",
    "            vars_mean_list.model_name.iat[index] = 'Sice_hom'\n",
    "\n",
    "vars_mean_list[3:] # echo variables (first rows are dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DEPHY output file\n",
    "\n",
    "Write a single file to contain all domain-mean scalar and profile outputs. This code expects the write directory to be pre-existing (already created by the user). In the case that this output will be committed to the comble-mip GitHub repository, see above \"Specify directory locations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create DEPHY output file\n",
    "dephy_filename = './' + my_gitdir + my_outfile\n",
    "if os.path.exists(dephy_filename):\n",
    "    os.remove(dephy_filename)\n",
    "    print('The file ' + dephy_filename + ' has been deleted successfully')    \n",
    "dephy_file = Dataset(dephy_filename,mode='w',format='NETCDF3_CLASSIC')\n",
    "\n",
    "# create global attributes\n",
    "dephy_file.title='DHARMA LES results for COMBLE-MIP case: fixed Nd and Ni'\n",
    "dephy_file.reference='https://github.com/ARM-Development/comble-mip'\n",
    "dephy_file.authors='Ann Fridlind (ann.fridlind@nasa.gov) and Florian Tornow (florian.tornow@nasa.gov)'\n",
    "dephy_file.source=input_filename\n",
    "dephy_file.version=dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "dephy_file.format_version='DEPHY SCM format version 1.6'\n",
    "dephy_file.script='convert_DHARMA_LES_output_to_dephy_format.ipynb'\n",
    "dephy_file.startDate=start_dtime\n",
    "dephy_file.force_geo=1\n",
    "dephy_file.surfaceType='ocean (after spin-up)'\n",
    "dephy_file.surfaceForcing='ts (after spin-up)'\n",
    "dephy_file.lat=str(dharma_params['Coriolis'].lat) + ' deg N'\n",
    "dephy_file.dx=str(dharma_params['geometry'].L_x/dharma_params['geometry'].nx) + ' m'\n",
    "dephy_file.dy=str(dharma_params['geometry'].L_y/dharma_params['geometry'].ny) + ' m'\n",
    "dephy_file.dz='see zf variable'\n",
    "dephy_file.nx=dharma_params['geometry'].nx\n",
    "dephy_file.ny=dharma_params['geometry'].ny\n",
    "dephy_file.nz=dharma_params['geometry'].nz\n",
    "\n",
    "# create dimensions\n",
    "nz = dharma_snds.sizes['zt']\n",
    "zf = dephy_file.createDimension('zf', nz)\n",
    "zf = dephy_file.createVariable('zf', np.float64, ('zf',))\n",
    "zf.units = 'm'\n",
    "zf.long_name = 'height'\n",
    "zf[:] = dharma_snds['zt'].data\n",
    "\n",
    "ze = dephy_file.createDimension('ze', nz)\n",
    "ze = dephy_file.createVariable('ze', np.float64, ('ze',))\n",
    "ze.units = 'm'\n",
    "ze.long_name = 'layer_top_height'\n",
    "ze[:] = dharma_snds['zw'].data[1:]\n",
    "\n",
    "nt = dharma_snds.sizes['time']\n",
    "time = dephy_file.createDimension('time', nt)\n",
    "time = dephy_file.createVariable('time', np.float64, ('time',))\n",
    "time.units = 'seconds since ' + dephy_file.startDate\n",
    "time.long_name = 'time'\n",
    "# find time step and build time in seconds\n",
    "delta_t = (dharma_snds['time'].data[1]-dharma_snds['time'].data[0])/np.timedelta64(1, \"s\")\n",
    "time[:] = np.arange(nt)*delta_t\n",
    "\n",
    "# create and fill variables\n",
    "for index in vars_mean_list.index[2:]:\n",
    "    std_name = vars_mean_list.standard_name.iat[index]\n",
    "#   print(std_name) # debug\n",
    "    var_name = vars_mean_list.variable_id.iat[index]\n",
    "    mod_name = vars_mean_list.model_name.iat[index]\n",
    "    c_factor = vars_mean_list.conv_factor.iat[index]\n",
    "    if vars_mean_list.dimensions.iat[index]=='time':\n",
    "        new_sca = dephy_file.createVariable(var_name, np.float64, ('time'))\n",
    "        new_sca.units = vars_mean_list.units.iat[index]\n",
    "        new_sca.long_name = std_name\n",
    "        if vars_mean_list.model_name.iat[index]!='missing data' and mod_name in dharma_scas:\n",
    "            new_sca[:] = dharma_scas[mod_name].data*c_factor\n",
    "    if vars_mean_list.dimensions.iat[index]=='time, height':\n",
    "        new_snd = dephy_file.createVariable(var_name, np.float64, ('time','zf'))\n",
    "        new_snd.units = vars_mean_list.units.iat[index]\n",
    "        new_snd.long_name = std_name\n",
    "        if vars_mean_list.model_name.iat[index]!='missing data' and mod_name in dharma_snds: \n",
    "            new_snd[:] = dharma_snds[mod_name].data*c_factor\n",
    "\n",
    "print(dephy_file)\n",
    "dephy_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dephy_check = xr.open_dataset(dephy_filename)\n",
    "dephy_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
